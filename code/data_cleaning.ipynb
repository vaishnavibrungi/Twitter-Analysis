{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cdd067",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a07422",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efe02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "import country_converter as coco\n",
    "import geonamescache\n",
    "import us\n",
    "import logging\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5755cf",
   "metadata": {},
   "source": [
    "**Read in both #workfromhome and #remotework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6ba2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfh_df = pd.read_csv(\"../dataset/tweet_df.csv\")\n",
    "rw_df = pd.read_csv(\"../dataset/remote_work.csv\")\n",
    "wfh_df_mixed = pd.read_csv(\"../dataset/wfh_mixed.csv\")\n",
    "rw_df_mixed = pd.read_csv(\"../dataset/remote_mixed.csv\")\n",
    "wfh_df_25 = pd.read_csv(\"../dataset/work_from_home_25.csv\")\n",
    "rw_df_25 = pd.read_csv(\"../dataset/remote_work_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae4a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.concat([rw_df,wfh_df,wfh_df_mixed,rw_df_mixed,wfh_df_25,rw_df_25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4782a22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39534, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc501a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17381"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_df[twitter_df.duplicated(\"tweet_id\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb42203",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df=twitter_df.drop_duplicates(subset=['tweet_id'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466452e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22153, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd734015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://catriscode.com/2021/03/02/extracting-or-removing-mentions-and-hashtags-in-tweets-using-python/\n",
    "#https://www.debuggex.com/cheatsheet/regex/python\n",
    "#https://stackoverflow.com/questions/50830214/remove-usernames-from-twitter-data-using-python/50830588\n",
    "#https://stackoverflow.com/questions/14081050/remove-all-forms-of-urls-from-a-given-string-in-python\n",
    "def remove_splchar(tweet):\n",
    "    tweet = tweet.lower() # Lowercases the string\n",
    "    tweet = re.sub('@[^\\s]+', ' ', tweet) # remove usernames\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', tweet) #remove URLs\n",
    "    tweet=re.sub('[^a-zA-Z#]', ' ', tweet) # remove special characters, numbers, punctuations\n",
    "    tweet = re.sub(\"#[A-Za-z0-9_]+\",\" \", tweet) #remove hashtags\n",
    "    tweet = re.sub(r\"\\s+\", \" \", str(tweet)) # replace double spaces with single space\n",
    "    return tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2463792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-spilt-a-sentence-into-list-of-words/\n",
    "#https://stackoverflow.com/questions/771918/how-do-i-do-word-stemming-or-lemmatization\n",
    "def lemmitize(tweet):\n",
    "    clean_column_list = []\n",
    "    wnl = WordNetLemmatizer()\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            clean_column_list.append(wnl.lemmatize(word)) \n",
    "    return \" \".join(clean_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cd72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Instantiate sentimnt analysis\n",
    "sent = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b522fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get polarity score of each tweet\n",
    "def getPolarity(tweet):\n",
    "    polarity_dic = sent(tweet)\n",
    "    if polarity_dic[0]['label'] == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61eac3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_by_country(code):\n",
    "    cities = []\n",
    "    for city in gc.get_cities().values():\n",
    "        if (city['countrycode'] == code) and (len(city['name']) > 3):\n",
    "            cities.append(city['name'])\n",
    "    return list(map(lambda x: x.lower(), cities));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c09f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstates_citiesz_of_usa():\n",
    "    usa_state_names = [state.name.lower() for state in us.states.STATES_AND_TERRITORIES]\n",
    "    return get_cities_by_country('US') + usa_state_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826c7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_state_cities_names = getstates_citiesz_of_usa()\n",
    "indian_cities = get_cities_by_country('IN')\n",
    "uk_cities = get_cities_by_country('GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3c9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForUSA(location):\n",
    "    country = location;\n",
    "    if location.lower().find('usa') != -1 or location.lower().find('united states of america') != -1 or location.lower().find('united states') != -1:\n",
    "        country = 'USA'\n",
    "    elif us.states.lookup(location.split(',')[-1].strip()) != None  or  location.lower().find('america') != -1 or location.lower().find('u.s.a.') != -1:  \n",
    "        country = 'USA'\n",
    "    else:    \n",
    "        for state_city in usa_state_cities_names:\n",
    "            if location.lower().find(state_city) != -1:\n",
    "                country = 'USA'\n",
    "                break;\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "765d1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_india(location):\n",
    "    country = location;\n",
    "    if location.lower().find('india') != -1:\n",
    "        country = 'India'\n",
    "    else:    \n",
    "        for cities in indian_cities:\n",
    "            if location.lower().find(cities) != -1:\n",
    "                country = 'India'\n",
    "                break;\n",
    "    return country    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2bbabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_uk(location):\n",
    "    country = location;\n",
    "    if location.lower().find('uk') != -1 or location.lower().find('britan') != -1 or location.lower().find('united kingdom') != -1:\n",
    "        country = 'United Kingdom'\n",
    "    else:    \n",
    "        for cities in uk_cities:\n",
    "            if location.lower().find(cities) != -1:\n",
    "                country = 'United Kingdom'\n",
    "                break;\n",
    "    return country    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94503fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_others(location):\n",
    "    country = location;  \n",
    "    dicts = gc.get_countries_by_names();\n",
    "    for country_name,data in dicts.items():\n",
    "        if location.lower().find(country_name.lower()) != -1:\n",
    "            return country_name\n",
    "    return country  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be64f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_none(location):\n",
    "    country = location;\n",
    "    if location == 'Europe' or location== 'Berlin, Deutschland' or location=='Sarrbr√ºken' or location=='Berlin'or location=='Prague'or location=='Bucharest' or location==\"Deutschland\" :\n",
    "        country = 'DE'\n",
    "    elif location== 'North West, England' or location=='England' or location=='South West, England'or location=='South East, England'or location=='Scotland'or location=='New England'or location=='North East, England'or location=='West Sussex - 01293 300 020':\n",
    "        country = 'GB'\n",
    "    elif location=='Rio de janeiro'or location=='S√£o Paulo, Brasil':\n",
    "        country = 'BR'\n",
    "    elif location== 'Toronto'or location== 'Edmonton, Alberta' or location=='Toronto, ON' or location=='Fort St. John'or location=='Montr√©al, Qu√©bec'or location=='Montr√©al, Qc':\n",
    "        country = 'CA'\n",
    "    elif location== 'Sydney, New South Wales' or location=='Carnegie, VIC, AU, 3163' or location=='LON | NYC | HKG  | SYD | SIN' or location=='Sydney':\n",
    "        country = 'AU'\n",
    "    elif location== 'NYC' or location== 'Silicon Valley & beyond' or location=='üá∫üá∏ M.4.G.4.üá∫üá∏  IFB4P ü¶Ö üèà' or location=='monkeytown' or location=='East Coast'or location=='Morgan City, LA 70380'or location=='Mid-Atlantic'or location=='14 locations in US. Cincy HQ.'or location=='MA: 40.758348,-73.986972'or location=='SF Bay Area'or location=='Appalachia':\n",
    "        country = 'US'\n",
    "    elif location== 'Iloilo City, Western Visayas' or location== 'Manila' or location=='Poblacion, Talibon, Bohol' or location=='Phlippines':\n",
    "        country = 'PH'\n",
    "    elif location== 'Bhopal Madhya Pradesh' or location== 'Thane'or location=='Kolkata, West Bengal' or location=='Chandigarh' or location=='‡¥ï‡µá‡¥∞‡¥≥‡¥Ç'or location=='Kolkata'or location=='Haryana':\n",
    "        country = 'IN'\n",
    "    elif location== 'G√∂teborg, Sverige':\n",
    "        country = 'SE'\n",
    "    elif location=='Ankara' or location== 'Istanbul'or location== 'Adana'or location=='Eski≈üehir, T√ºrkiye'or location=='Izmir':\n",
    "        country = 'TR'\n",
    "    elif location== 'M√©xico':\n",
    "        country = 'MX'\n",
    "    elif location=='Tokyo' or location=='anywhere üåç / Born in Tokyoüóº':\n",
    "        country = 'JP'\n",
    "    elif location=='Madrid'or location=='Barcelona, Espa√±a'or location=='Espa√±a'or location=='Madrid, Comunidad de Madrid':\n",
    "        country = 'ES'\n",
    "    elif location=='Kampala':\n",
    "        country = 'UG'\n",
    "    elif location== 'Buenos Aires':\n",
    "        country = 'AR'\n",
    "    elif location=='UAE'or location=='Dubai, UAE':\n",
    "        country = 'AE'\n",
    "    elif location=='Bali, Indonesien' or location=='NYC - LON - SIN - BALI':\n",
    "        country = 'ID'\n",
    "    elif location== 'Brunssum':\n",
    "        country = 'NL'\n",
    "    elif location== 'Bloemfontein, ZA'or location=='Cape Town'or location=='137 Hennie Alberts Brackenhurs':\n",
    "        country = 'ZA'\n",
    "    elif location== 'Caracas':\n",
    "        country = 'VE'\n",
    "    elif location== 'Z√ºrich, Schweiz':\n",
    "        country = 'CH'\n",
    "    elif location== 'Harare':\n",
    "        country = 'ZW'\n",
    "    elif location== 'Jhelum':\n",
    "        country = 'PK'\n",
    "    elif location== 'Nairobi':\n",
    "        country = 'KE'\n",
    "    return country  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950b382",
   "metadata": {},
   "source": [
    "**#workfromhome  dataframe cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a7f86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "twitter_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4134641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üè° #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Fri Jul 16 23:43:03 +0000 2021</td>\n",
       "      <td>1416181616846811137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>Fri Jul 16 23:42:07 +0000 2021</td>\n",
       "      <td>1416181380279635970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>Fri Jul 16 23:41:30 +0000 2021</td>\n",
       "      <td>1416181225979473920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  üè° #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "\n",
       "                    user_location                 tweet_posted_on  \\\n",
       "0                    New York, NY  Fri Jul 16 23:43:03 +0000 2021   \n",
       "1               London | New York  Fri Jul 16 23:42:07 +0000 2021   \n",
       "2  Sydney | Hong Kong | Singapore  Fri Jul 16 23:41:30 +0000 2021   \n",
       "\n",
       "              tweet_id  \n",
       "0  1416181616846811137  \n",
       "1  1416181380279635970  \n",
       "2  1416181225979473920  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to confirm if the column got deleted \n",
    "twitter_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6db9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22153, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df8bbc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             0\n",
       "user_location      1\n",
       "tweet_posted_on    0\n",
       "tweet_id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "twitter_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2163edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             object\n",
       "user_location      object\n",
       "tweet_posted_on    object\n",
       "tweet_id            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatypes\n",
    "twitter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0fb6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column to be datetime dtype\n",
    "#https://stackoverflow.com/questions/50503033/remove-minutes-and-hours-from-series\n",
    "twitter_df['tweet_posted_on'] = pd.to_datetime(twitter_df['tweet_posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3f088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/52673285/performance-of-pandas-apply-vs-np-vectorize-to-create-new-column-from-existing-c/52674448#52674448\n",
    "#Create a new column for processed tweets\n",
    "twitter_df['cleaned_tweets'] = np.vectorize(remove_splchar)(twitter_df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e19677b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of words which have more than 3 letters\n",
    "twitter_df['cleaned_tweets'] = twitter_df['cleaned_tweets'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2f0fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place new lists of lemmitized words into the 'cleaned_tweets' column in the dataframe\n",
    "twitter_df['cleaned_tweets'] = twitter_df['cleaned_tweets'].map(lemmitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b32e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'polarity' to save tweet polarity score\n",
    "twitter_df['polarity'] = twitter_df['cleaned_tweets'].map(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "add984a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['user_location_cleaned'] = twitter_df['user_location'].astype(str).map(checkForUSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e6b2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['user_location_cleaned'] = twitter_df['user_location_cleaned'].astype(str).map(check_for_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "604375ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['user_location_cleaned'] = twitter_df['user_location_cleaned'].astype(str).map(check_for_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd7e7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['user_location_cleaned'] = twitter_df['user_location_cleaned'].astype(str).map(check_for_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec0b4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df['user_location_cleaned'] = twitter_df['user_location_cleaned'].astype(str).map(check_for_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72eedc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_logger = coco.logging.getLogger()\n",
    "coco_logger.setLevel(logging.CRITICAL) #Print only the critical loggers\n",
    "twitter_df['user_location_cleaned'] = coco.convert(names=twitter_df['user_location_cleaned'].tolist(), to='ISO2', not_found='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "549198d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22153, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4e1e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column order\n",
    "twitter_df = twitter_df[['tweet_id','tweet_posted_on','tweets','cleaned_tweets','user_location','user_location_cleaned','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7986505a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416181616846811137</td>\n",
       "      <td>2021-07-16 23:43:03+00:00</td>\n",
       "      <td>üè° #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>rise slowly becoming normal mean need remote t...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416181380279635970</td>\n",
       "      <td>2021-07-16 23:42:07+00:00</td>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>opportunity join fantastic team tech fast pace...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416181225979473920</td>\n",
       "      <td>2021-07-16 23:41:30+00:00</td>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>good news open excellent report remote advert ...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>HK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1416181616846811137 2021-07-16 23:43:03+00:00   \n",
       "1  1416181380279635970 2021-07-16 23:42:07+00:00   \n",
       "2  1416181225979473920 2021-07-16 23:41:30+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  üè° #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  rise slowly becoming normal mean need remote t...   \n",
       "1  opportunity join fantastic team tech fast pace...   \n",
       "2  good news open excellent report remote advert ...   \n",
       "\n",
       "                    user_location user_location_cleaned  polarity  \n",
       "0                    New York, NY                    US         1  \n",
       "1               London | New York                    US         1  \n",
       "2  Sydney | Hong Kong | Singapore                    HK         1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe\n",
    "twitter_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00bd517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in a 'dataset' folder with a name 'twitter_df.csv'\n",
    "twitter_df.to_csv('../dataset/twitter_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46bbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
