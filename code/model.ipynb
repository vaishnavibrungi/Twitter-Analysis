{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "89e4db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f789f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in 'twitter_df'\n",
    "twitter_df = pd.read_csv(\"../dataset/twitter_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "85d70a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22153, 8)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "54fcef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9a72c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create our contextual stop words\n",
    "# stops = [\"online\", \"home\", \"remote\", \"work\", \"working\",\"pandemic\",\"business\", \\\n",
    "#                \"internet\", \"remotework\", \"online\",\"team\",\"office\",\"company\",\"hybrid\",\"employee\",\"looking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4e759b75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4557"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_df[twitter_df.duplicated(\"tweets\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8372d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originaltweets =twitter_df.drop_duplicates(subset=['tweets'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "996c1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "originaltweets = twitter_df[~twitter_df['tweets'].str.contains('RT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "42a8546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "originaltweets = originaltweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "af566c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "originaltweets =originaltweets.drop_duplicates(subset=['cleaned_tweets'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "95b03e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rise slowly becoming normal which mean need remote training also growing here benefit challenge best practice when come successfully training remote employee    1\n",
       "need adapt your process remote work continue one designed office based work lean sigma best achieve this                                                         1\n",
       "prevent your home router from being targeted hacker                                                                                                              1\n",
       "good news open this excellent report from remote advert soaring this provides encouragement seeker australia share remote job indust                             1\n",
       "four way energize post pandemic workforce                                                                                                                        1\n",
       "                                                                                                                                                                ..\n",
       "here stay even with vaccine say former cnbc                                                                                                                      1\n",
       "what keep your talent insideout community share idea that help retain your staff during this turnover tsunami                                                    1\n",
       "remote work taking lead clevertech android developer                                                                                                             1\n",
       "sorry this real reason meeting much better passage wait until finished connecting this virtual auction coming soon atom                                          1\n",
       "this save your inbox from exploding                                                                                                                              1\n",
       "Name: cleaned_tweets, Length: 10780, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaltweets['cleaned_tweets'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "682e8caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rise slowly becoming normal which mean need re...\n",
       "1    opportunity join fantastic team tech fast pace...\n",
       "2    good news open this excellent report from remo...\n",
       "3            four way energize post pandemic workforce\n",
       "4    these tool that will save your google meet too...\n",
       "Name: cleaned_tweets, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = originaltweets['cleaned_tweets']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da921fe",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b032455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document\n",
    "#https://stackoverflow.com/questions/27697766/understanding-min-df-and-max-df-in-scikit-countvectorizer\n",
    "cv = CountVectorizer(max_features=5000, min_df=3, stop_words=stopwords.words('english')) \n",
    "X_cv = cv.fit_transform(X.values.astype('U'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "109552bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10781,)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4b9f530b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3783"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "22a9aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv_df = pd.DataFrame(X_cv.toarray(), columns = cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7c976617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10781, 3783)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "012c92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([originaltweets, X_cv_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f8275aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c323bd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "      <th>polarity</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>...</th>\n",
       "      <th>yorker</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoho</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416181616846811137</td>\n",
       "      <td>2021-07-16 23:43:03+00:00</td>\n",
       "      <td>üè° #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>rise slowly becoming normal which mean need re...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416181380279635970</td>\n",
       "      <td>2021-07-16 23:42:07+00:00</td>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>opportunity join fantastic team tech fast pace...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416181225979473920</td>\n",
       "      <td>2021-07-16 23:41:30+00:00</td>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>good news open this excellent report from remo...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>HK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416180635903868934</td>\n",
       "      <td>2021-07-16 23:39:09+00:00</td>\n",
       "      <td>Four Ways to Energize a Post-Pandemic Workforc...</td>\n",
       "      <td>four way energize post pandemic workforce</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1416180231350759425</td>\n",
       "      <td>2021-07-16 23:37:33+00:00</td>\n",
       "      <td>üöë These are the tools that will save your #Rem...</td>\n",
       "      <td>these tool that will save your google meet too...</td>\n",
       "      <td>Duluth, GA</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 3790 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id            tweet_posted_on  \\\n",
       "0  1416181616846811137  2021-07-16 23:43:03+00:00   \n",
       "1  1416181380279635970  2021-07-16 23:42:07+00:00   \n",
       "2  1416181225979473920  2021-07-16 23:41:30+00:00   \n",
       "3  1416180635903868934  2021-07-16 23:39:09+00:00   \n",
       "4  1416180231350759425  2021-07-16 23:37:33+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  üè° #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "3  Four Ways to Energize a Post-Pandemic Workforc...   \n",
       "4  üöë These are the tools that will save your #Rem...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  rise slowly becoming normal which mean need re...   \n",
       "1  opportunity join fantastic team tech fast pace...   \n",
       "2  good news open this excellent report from remo...   \n",
       "3          four way energize post pandemic workforce   \n",
       "4  these tool that will save your google meet too...   \n",
       "\n",
       "                    user_location user_location_cleaned  polarity  ability  \\\n",
       "0                    New York, NY                    US         1        0   \n",
       "1               London | New York                    US         1        0   \n",
       "2  Sydney | Hong Kong | Singapore                    HK         1        0   \n",
       "3                     Chicago, IL                    US         1        0   \n",
       "4                      Duluth, GA                    US         0        0   \n",
       "\n",
       "   able  abroad  ...  yorker  young  younger  youth  youtube  zdnet  zero  \\\n",
       "0     0       0  ...       0      0        0      0        0      0     0   \n",
       "1     0       0  ...       0      0        0      0        0      0     0   \n",
       "2     0       0  ...       0      0        0      0        0      0     0   \n",
       "3     0       0  ...       0      0        0      0        0      0     0   \n",
       "4     0       0  ...       0      0        0      0        0      0     0   \n",
       "\n",
       "   zoho  zone  zoom  \n",
       "0     0     0     0  \n",
       "1     0     0     0  \n",
       "2     0     0     0  \n",
       "3     0     0     0  \n",
       "4     0     0     0  \n",
       "\n",
       "[5 rows x 3790 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0bfeab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_col = df.columns[7:]\n",
    "cv_col_names = df[cv_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "29be78c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05370029, -0.06334373, -0.01668367, ..., -0.01668367,\n",
       "        -0.05022671, -0.08211041]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv=cv_col_names\n",
    "sc = StandardScaler()\n",
    "X_cv_sc = sc.fit_transform(X_cv)\n",
    "X_cv_sc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1a83e8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academia</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>accelerating</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>...</th>\n",
       "      <th>yorker</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoho</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 3783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  abroad  absence  absolutely  academia  accelerate  \\\n",
       "0        0     0       0        0           0         0           0   \n",
       "1        0     0       0        0           0         0           0   \n",
       "2        0     0       0        0           0         0           0   \n",
       "3        0     0       0        0           0         0           0   \n",
       "4        0     0       0        0           0         0           0   \n",
       "\n",
       "   accelerated  accelerating  acceleration  ...  yorker  young  younger  \\\n",
       "0            0             0             0  ...       0      0        0   \n",
       "1            0             0             0  ...       0      0        0   \n",
       "2            0             0             0  ...       0      0        0   \n",
       "3            0             0             0  ...       0      0        0   \n",
       "4            0             0             0  ...       0      0        0   \n",
       "\n",
       "   youth  youtube  zdnet  zero  zoho  zone  zoom  \n",
       "0      0        0      0     0     0     0     0  \n",
       "1      0        0      0     0     0     0     0  \n",
       "2      0        0      0     0     0     0     0  \n",
       "3      0        0      0     0     0     0     0  \n",
       "4      0        0      0     0     0     0     0  \n",
       "\n",
       "[5 rows x 3783 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "46edfaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4, random_state=42)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km_cv = KMeans(n_clusters=4, random_state=42)\n",
    "km_cv.fit(X_cv_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ef27d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.1923824839437538\n",
      "4 0.04169385979130381\n",
      "5 0.01768652567155152\n",
      "6 0.014508429105991273\n",
      "7 0.0762021777144707\n",
      "8 0.07824298712028345\n",
      "9 -0.2376116037641056\n",
      "10 0.06771088483817042\n",
      "11 -0.04676873164537919\n",
      "12 0.07790537461570765\n",
      "13 -0.017337324221319773\n",
      "14 -0.032976036985163354\n",
      "15 -0.11585384050410222\n"
     ]
    }
   ],
   "source": [
    "for n in range(3, 16):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    kmeans.fit(X_cv_sc)\n",
    "    print(n,silhouette_score(X_cv_sc, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e737ce70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05370029, -0.06334373, -0.01668367, ..., -0.01668367,\n",
       "        -0.05022671, -0.08211041],\n",
       "       [ 0.00043687,  0.00051533,  0.00013573, ...,  0.00013573,\n",
       "         0.00040861,  0.000668  ],\n",
       "       [-0.05370029, -0.06334373, -0.01668367, ..., -0.01668367,\n",
       "        -0.05022671, -0.08211041],\n",
       "       [-0.05370029, -0.06334373, -0.01668367, ..., -0.01668367,\n",
       "        -0.05022671, -0.08211041]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_cv.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "46b7b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['km']=km_cv.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "943d53eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10694\n",
       "2       65\n",
       "0       19\n",
       "3        3\n",
       "Name: km, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['km'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cf45c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04169385979130381"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(X_cv_sc, km_cv.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "483d16c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "      <th>polarity</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoho</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>1414648031744516102</td>\n",
       "      <td>2021-07-12 18:09:08+00:00</td>\n",
       "      <td>Come help build a spot-market for hashrate, no...</td>\n",
       "      <td>come help build spot market hashrate dissimila...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>1416524641888256002</td>\n",
       "      <td>2021-07-17 22:26:07+00:00</td>\n",
       "      <td>Come help build a spot-market for hashrate, no...</td>\n",
       "      <td>come help build spot market hashrate dissimila...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>1416523133180383237</td>\n",
       "      <td>2021-07-17 22:20:07+00:00</td>\n",
       "      <td>Come help build a spot-market for hashrate, no...</td>\n",
       "      <td>come help build spot market hashrate dissimila...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 3791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id            tweet_posted_on  \\\n",
       "2906  1414648031744516102  2021-07-12 18:09:08+00:00   \n",
       "7264  1416524641888256002  2021-07-17 22:26:07+00:00   \n",
       "7266  1416523133180383237  2021-07-17 22:20:07+00:00   \n",
       "\n",
       "                                                 tweets  \\\n",
       "2906  Come help build a spot-market for hashrate, no...   \n",
       "7264  Come help build a spot-market for hashrate, no...   \n",
       "7266  Come help build a spot-market for hashrate, no...   \n",
       "\n",
       "                                         cleaned_tweets      user_location  \\\n",
       "2906  come help build spot market hashrate dissimila...             Remote   \n",
       "7264  come help build spot market hashrate dissimila...             Remote   \n",
       "7266  come help build spot market hashrate dissimila...  London | New York   \n",
       "\n",
       "     user_location_cleaned  polarity  ability  able  abroad  ...  young  \\\n",
       "2906                  None         0        0     0       0  ...      0   \n",
       "7264                  None         0        0     0       0  ...      0   \n",
       "7266                    US         0        0     0       0  ...      0   \n",
       "\n",
       "      younger  youth  youtube  zdnet  zero  zoho  zone  zoom  km  \n",
       "2906        0      0        0      0     0     0     0     0   3  \n",
       "7264        0      0        0      0     0     0     0     0   3  \n",
       "7266        0      0        0      0     0     0     0     0   3  \n",
       "\n",
       "[3 rows x 3791 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['km'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c32cddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "come help build spot market hashrate dissimilar compute power version henry remote cloud infrastructure engineer kubernetes                                1\n",
       "come help build spot market hashrate dissimilar compute power version henry remote data engineer equity                                                    1\n",
       "come help build spot market hashrate dissimilar compute power version henry check this remote data engineer role working with data elasticsearch hadoop    1\n",
       "Name: cleaned_tweets, dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['km'] == 3]['cleaned_tweets'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7c1f1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies_by_cluster = df.groupby('km').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f6e5afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>polarity</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academia</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>...</th>\n",
       "      <th>yorker</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoho</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.689141e+19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.514698e+22</td>\n",
       "      <td>5244.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.207637e+19</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.247696e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 3785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id  polarity  ability  able  abroad  absence  absolutely  \\\n",
       "km                                                                       \n",
       "0   2.689141e+19       1.0      0.0   0.0     0.0      0.0         0.0   \n",
       "1   1.514698e+22    5244.0     31.0  45.0     3.0      4.0        12.0   \n",
       "2   9.207637e+19      30.0      0.0   0.0     0.0      0.0         0.0   \n",
       "3   4.247696e+18       0.0      0.0   0.0     0.0      0.0         0.0   \n",
       "\n",
       "    academia  accelerate  accelerated  ...  yorker  young  younger  youth  \\\n",
       "km                                     ...                                  \n",
       "0        0.0         0.0          0.0  ...     0.0    0.0      0.0    0.0   \n",
       "1        5.0         4.0         13.0  ...     3.0   19.0      4.0    3.0   \n",
       "2        0.0         0.0          0.0  ...     0.0    0.0      0.0    0.0   \n",
       "3        0.0         0.0          0.0  ...     0.0    0.0      0.0    0.0   \n",
       "\n",
       "    youtube  zdnet  zero  zoho  zone  zoom  \n",
       "km                                          \n",
       "0       0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "1      39.0    3.0  35.0   3.0  29.0  76.0  \n",
       "2       0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "3       0.0    0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4 rows x 3785 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies_by_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b336c3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " warn\n",
      " horizon\n",
      " putting\n",
      " staying\n",
      " cyber\n",
      " potential\n",
      " secure\n",
      " risk\n",
      " expert\n",
      " contact\n",
      " anywhere\n",
      " pandemic\n",
      " tip\n",
      " help\n",
      " employee\n",
      " work\n",
      " miller\n",
      " corp\n",
      " consulting\n",
      " industrial\n",
      "Cluster 1:\n",
      " apply\n",
      " hiring\n",
      " remotely\n",
      " today\n",
      " working\n",
      " manager\n",
      " developer\n",
      " product\n",
      " start\n",
      " customer\n",
      " great\n",
      " post\n",
      " stay\n",
      " money\n",
      " week\n",
      " look\n",
      " experience\n",
      " opportunity\n",
      " competitive\n",
      " lead\n",
      "Cluster 2:\n",
      " small\n",
      " effort\n",
      " rabbitrun\n",
      " bureaucracy\n",
      " sized\n",
      " business\n",
      " decided\n",
      " baby\n",
      " owner\n",
      " patio\n",
      " enjoyable\n",
      " kitchen\n",
      " located\n",
      " teamwork\n",
      " purpose\n",
      " folding\n",
      " writes\n",
      " yellow\n",
      " newport\n",
      " scalable\n",
      "Cluster 3:\n",
      " dissimilar\n",
      " hashrate\n",
      " compute\n",
      " henry\n",
      " version\n",
      " spot\n",
      " elasticsearch\n",
      " power\n",
      " market\n",
      " build\n",
      " come\n",
      " kubernetes\n",
      " data\n",
      " infrastructure\n",
      " equity\n",
      " help\n",
      " engineer\n",
      " cloud\n",
      " role\n",
      " remote\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/27889873/clustering-text-documents-using-scikit-learn-kmeans-in-python\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km_cv.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = cv.get_feature_names()\n",
    "for i in range(4):\n",
    "    print (\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print( ' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf1d11",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "041f41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37593293/how-to-get-tfidf-with-pandas-dataframe\n",
    "tfidf = TfidfVectorizer(max_features=5000,stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b9f726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(X.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "187dbc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "719a44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "48f1fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([originaltweets, X_tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "82b50d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6df5c4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "      <th>polarity</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>...</th>\n",
       "      <th>yorker</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoho</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416181616846811137</td>\n",
       "      <td>2021-07-16 23:43:03+00:00</td>\n",
       "      <td>üè° #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>rise slowly becoming normal which mean need re...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416181380279635970</td>\n",
       "      <td>2021-07-16 23:42:07+00:00</td>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>opportunity join fantastic team tech fast pace...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416181225979473920</td>\n",
       "      <td>2021-07-16 23:41:30+00:00</td>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>good news open this excellent report from remo...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>HK</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416180635903868934</td>\n",
       "      <td>2021-07-16 23:39:09+00:00</td>\n",
       "      <td>Four Ways to Energize a Post-Pandemic Workforc...</td>\n",
       "      <td>four way energize post pandemic workforce</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1416180231350759425</td>\n",
       "      <td>2021-07-16 23:37:33+00:00</td>\n",
       "      <td>üöë These are the tools that will save your #Rem...</td>\n",
       "      <td>these tool that will save your google meet too...</td>\n",
       "      <td>Duluth, GA</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id            tweet_posted_on  \\\n",
       "0  1416181616846811137  2021-07-16 23:43:03+00:00   \n",
       "1  1416181380279635970  2021-07-16 23:42:07+00:00   \n",
       "2  1416181225979473920  2021-07-16 23:41:30+00:00   \n",
       "3  1416180635903868934  2021-07-16 23:39:09+00:00   \n",
       "4  1416180231350759425  2021-07-16 23:37:33+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  üè° #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "3  Four Ways to Energize a Post-Pandemic Workforc...   \n",
       "4  üöë These are the tools that will save your #Rem...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  rise slowly becoming normal which mean need re...   \n",
       "1  opportunity join fantastic team tech fast pace...   \n",
       "2  good news open this excellent report from remo...   \n",
       "3          four way energize post pandemic workforce   \n",
       "4  these tool that will save your google meet too...   \n",
       "\n",
       "                    user_location user_location_cleaned  polarity  ability  \\\n",
       "0                    New York, NY                    US         1      0.0   \n",
       "1               London | New York                    US         1      0.0   \n",
       "2  Sydney | Hong Kong | Singapore                    HK         1      0.0   \n",
       "3                     Chicago, IL                    US         1      0.0   \n",
       "4                      Duluth, GA                    US         0      0.0   \n",
       "\n",
       "   able  abroad  ...  yorker  young  younger  youth  youtube  zdnet  zero  \\\n",
       "0   0.0     0.0  ...     0.0    0.0      0.0    0.0      0.0    0.0   0.0   \n",
       "1   0.0     0.0  ...     0.0    0.0      0.0    0.0      0.0    0.0   0.0   \n",
       "2   0.0     0.0  ...     0.0    0.0      0.0    0.0      0.0    0.0   0.0   \n",
       "3   0.0     0.0  ...     0.0    0.0      0.0    0.0      0.0    0.0   0.0   \n",
       "4   0.0     0.0  ...     0.0    0.0      0.0    0.0      0.0    0.0   0.0   \n",
       "\n",
       "   zoho  zone  zoom  \n",
       "0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5007 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5099501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_col = df1.columns[7:]\n",
    "tfidf_col_names = df1[tfidf_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b0031040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05189852, -0.0618364 , -0.01577257, ..., -0.01653625,\n",
       "        -0.05011193, -0.07889675]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf=tfidf_col_names\n",
    "sc = StandardScaler()\n",
    "X_tfidf_sc = sc.fit_transform(X_tfidf)\n",
    "X_tfidf_sc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "550ede4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=15, random_state=42)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km_tfidf = KMeans(n_clusters=15, random_state=42)\n",
    "km_tfidf.fit(X_tfidf_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "45276ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -53853204.150502466 0.13619154215049453\n",
      "4 -53784655.24951849 0.1403690832910357\n",
      "5 -53822639.56548784 0.0025900435378184493\n",
      "6 -53767219.906884596 -0.07658938270820985\n",
      "7 -53788770.83686704 -0.07345027989711467\n",
      "8 -53707294.91039878 -0.07294968911090385\n",
      "9 -53686976.698391624 -0.0757667773964295\n",
      "10 -53692503.896410026 -0.057694497174397244\n",
      "11 -53696611.78304146 0.0043156890992473605\n",
      "12 -53670807.706592105 -0.04295640326806475\n",
      "13 -53652955.80997499 -0.08739204369348107\n",
      "14 -53617808.062422514 -0.07361686569212382\n",
      "15 -53546938.43827386 -0.06863490276000554\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 16):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(X_tfidf_sc)\n",
    "    print(i, kmeans.score(X_tfidf_sc), silhouette_score(X_tfidf_sc, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7a5562a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05189852, -0.0618364 , -0.01577257, ..., -0.01653625,\n",
       "        -0.05011193, -0.07889675],\n",
       "       [ 0.00622114,  0.00611376,  0.00189068, ...,  0.00198222,\n",
       "        -0.00679986,  0.00945745],\n",
       "       [-0.05189852, -0.0618364 , -0.01577257, ..., -0.01653625,\n",
       "        -0.05011193, -0.07889675],\n",
       "       ...,\n",
       "       [-0.05189852, -0.0618364 , -0.01577257, ..., -0.01653625,\n",
       "        -0.05011193, -0.07889675],\n",
       "       [-0.05189852, -0.0618364 , -0.01577257, ..., -0.01653625,\n",
       "        -0.05011193, -0.07889675],\n",
       "       [-0.05189852, -0.04845096, -0.01577257, ..., -0.01653625,\n",
       "        -0.05011193, -0.07889675]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_tfidf.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a895581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['km']=km_tfidf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a507463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     9627\n",
       "14     934\n",
       "4      156\n",
       "2       17\n",
       "8       12\n",
       "11      10\n",
       "13       9\n",
       "0        3\n",
       "12       3\n",
       "10       2\n",
       "7        2\n",
       "3        2\n",
       "6        2\n",
       "9        1\n",
       "5        1\n",
       "Name: km, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['km'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e01963bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06863490276000554"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(X_tfidf_sc, km_tfidf.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "88757b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_by_cluster = df1.groupby('km').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9e389aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>polarity</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academia</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>...</th>\n",
       "      <th>yorker</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoho</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.245340e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.363577e+22</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>8.955053</td>\n",
       "      <td>12.425575</td>\n",
       "      <td>1.504476</td>\n",
       "      <td>1.651445</td>\n",
       "      <td>1.192606</td>\n",
       "      <td>1.544211</td>\n",
       "      <td>0.726604</td>\n",
       "      <td>0.891511</td>\n",
       "      <td>...</td>\n",
       "      <td>1.438302</td>\n",
       "      <td>6.172018</td>\n",
       "      <td>1.925429</td>\n",
       "      <td>0.364912</td>\n",
       "      <td>6.458717</td>\n",
       "      <td>1.38673</td>\n",
       "      <td>7.313449</td>\n",
       "      <td>1.2647</td>\n",
       "      <td>7.458538</td>\n",
       "      <td>23.928749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.407112e+19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.833162e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.209219e+20</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.155528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.205396</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id  polarity   ability       able    abroad   absence  absolute  \\\n",
       "km                                                                              \n",
       "0   4.245340e+18       3.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "1   1.363577e+22    4861.0  8.955053  12.425575  1.504476  1.651445  1.192606   \n",
       "2   2.407112e+19       6.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "3   2.833162e+18       0.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "4   2.209219e+20      55.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    absolutely  academia  accelerate  ...    yorker     young   younger  \\\n",
       "km                                    ...                                 \n",
       "0     0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1     1.544211  0.726604    0.891511  ...  1.438302  6.172018  1.925429   \n",
       "2     0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4     0.000000  1.155528    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "       youth   youtube    zdnet      zero    zoho      zone       zoom  \n",
       "km                                                                      \n",
       "0   0.000000  0.000000  0.00000  0.000000  0.0000  0.000000   0.000000  \n",
       "1   0.364912  6.458717  1.38673  7.313449  1.2647  7.458538  23.928749  \n",
       "2   0.000000  0.000000  0.00000  0.000000  0.0000  0.000000   0.000000  \n",
       "3   0.000000  0.000000  0.00000  0.000000  0.0000  0.000000   0.000000  \n",
       "4   0.000000  0.000000  0.00000  0.000000  0.0000  2.205396   0.000000  \n",
       "\n",
       "[5 rows x 5002 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_by_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "260b6bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " designing\n",
      " elementor\n",
      " landing\n",
      " watching\n",
      " segment\n",
      " converting\n",
      " securely\n",
      " page\n",
      " return\n",
      " transition\n",
      " helping\n",
      " meet\n",
      " high\n",
      " expert\n",
      " shift\n",
      " leader\n",
      " making\n",
      " space\n",
      " office\n",
      " tip\n",
      "Cluster 1:\n",
      " office\n",
      " working\n",
      " work\n",
      " employee\n",
      " home\n",
      " company\n",
      " hybrid\n",
      " time\n",
      " competitive\n",
      " meeting\n",
      " back\n",
      " productivity\n",
      " many\n",
      " compensation\n",
      " workplace\n",
      " benefit\n",
      " tip\n",
      " future\n",
      " keep\n",
      " read\n",
      "Cluster 2:\n",
      " rule\n",
      " publication\n",
      " crash\n",
      " sunlight\n",
      " welcoming\n",
      " planned\n",
      " regulation\n",
      " rely\n",
      " dropping\n",
      " guideline\n",
      " minister\n",
      " toddler\n",
      " headline\n",
      " successful\n",
      " amount\n",
      " whose\n",
      " upgrade\n",
      " ground\n",
      " earnings\n",
      " updated\n",
      "Cluster 3:\n",
      " loophole\n",
      " exploiting\n",
      " ordinary\n",
      " algorithm\n",
      " perpetual\n",
      " continuous\n",
      " clip\n",
      " secret\n",
      " month\n",
      " revenue\n",
      " exactly\n",
      " following\n",
      " right\n",
      " enjoy\n",
      " video\n",
      " income\n",
      " create\n",
      " people\n",
      " learn\n",
      " find\n",
      "Cluster 4:\n",
      " alert\n",
      " market\n",
      " representative\n",
      " europe\n",
      " cvedia\n",
      " argyle\n",
      " italian\n",
      " development\n",
      " remotely\n",
      " europea\n",
      " compute\n",
      " hashrate\n",
      " dissimilar\n",
      " django\n",
      " sale\n",
      " unitedhealth\n",
      " telemarketing\n",
      " metabolic\n",
      " impacting\n",
      " outbound\n",
      "Cluster 5:\n",
      " temora\n",
      " midwife\n",
      " registered\n",
      " title\n",
      " moama\n",
      " bahut\n",
      " revolving\n",
      " potluck\n",
      " circleci\n",
      " cashout\n",
      " rubanm\n",
      " keywords\n",
      " tata\n",
      " mbps\n",
      " onpassive\n",
      " readiness\n",
      " radiant\n",
      " servicenow\n",
      " permalinks\n",
      " corresponding\n",
      "Cluster 6:\n",
      " dyna\n",
      " handmade\n",
      " glass\n",
      " real\n",
      " sign\n",
      " home\n",
      " moama\n",
      " revolving\n",
      " bahut\n",
      " keywords\n",
      " potluck\n",
      " cashout\n",
      " circleci\n",
      " rubanm\n",
      " mbps\n",
      " sticker\n",
      " corresponding\n",
      " onpassive\n",
      " readiness\n",
      " tata\n",
      "Cluster 7:\n",
      " nailed\n",
      " logo\n",
      " loved\n",
      " enjoyed\n",
      " dog\n",
      " discount\n",
      " core\n",
      " seems\n",
      " miss\n",
      " small\n",
      " issue\n",
      " high\n",
      " please\n",
      " five\n",
      " watch\n",
      " must\n",
      " well\n",
      " happy\n",
      " video\n",
      " remote\n",
      "Cluster 8:\n",
      " paying\n",
      " hottest\n",
      " cheaper\n",
      " mercury\n",
      " stat\n",
      " high\n",
      " kiwi\n",
      " australian\n",
      " highest\n",
      " emily\n",
      " resident\n",
      " thankful\n",
      " directly\n",
      " job\n",
      " higher\n",
      " sabio\n",
      " compared\n",
      " city\n",
      " hurt\n",
      " bill\n",
      "Cluster 9:\n",
      " excitement\n",
      " doorbell\n",
      " random\n",
      " entered\n",
      " telesales\n",
      " quickly\n",
      " door\n",
      " already\n",
      " weekend\n",
      " without\n",
      " normal\n",
      " feel\n",
      " world\n",
      " year\n",
      " like\n",
      " today\n",
      " moama\n",
      " revolving\n",
      " bahut\n",
      " keywords\n",
      "Cluster 10:\n",
      " try\n",
      " tongue\n",
      " filipino\n",
      " twister\n",
      " cyberbacker\n",
      " part\n",
      " apply\n",
      " today\n",
      " revolving\n",
      " bahut\n",
      " moama\n",
      " potluck\n",
      " circleci\n",
      " cashout\n",
      " keywords\n",
      " rubanm\n",
      " krazy\n",
      " sticker\n",
      " permalinks\n",
      " corresponding\n",
      "Cluster 11:\n",
      " fail\n",
      " determined\n",
      " mantra\n",
      " succeed\n",
      " downfall\n",
      " makemoney\n",
      " smile\n",
      " citizen\n",
      " makemoneyfromhome\n",
      " truth\n",
      " mask\n",
      " face\n",
      " winning\n",
      " wear\n",
      " ensure\n",
      " leaving\n",
      " called\n",
      " whether\n",
      " sense\n",
      " interview\n",
      "Cluster 12:\n",
      " scandalous\n",
      " severe\n",
      " sunak\n",
      " pensioner\n",
      " raiding\n",
      " pension\n",
      " raid\n",
      " rishi\n",
      " backlash\n",
      " april\n",
      " paul\n",
      " avoiding\n",
      " attempt\n",
      " typical\n",
      " peter\n",
      " stop\n",
      " face\n",
      " increase\n",
      " must\n",
      " bahut\n",
      "Cluster 13:\n",
      " audiobook\n",
      " absolutely\n",
      " framework\n",
      " million\n",
      " learner\n",
      " used\n",
      " selling\n",
      " load\n",
      " uncover\n",
      " step\n",
      " student\n",
      " zero\n",
      " discover\n",
      " product\n",
      " help\n",
      " join\n",
      " right\n",
      " find\n",
      " download\n",
      " today\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km_tfidf.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names()\n",
    "for i in range(14):\n",
    "    print (\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print( ' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b7ef5",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "07bb8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.load('text8')\n",
    "model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a2330cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code written by Caroline\n",
    "def get_avg_vec(text):\n",
    "    try:\n",
    "        # make a list of only the words in the document that are in the word2vec vocabulary\n",
    "        valid_words = [word for word in text.lower().split() if word in model.wv.key_to_index]\n",
    "        print(model.wv.vocab)\n",
    "        if len(valid_words) == 0:\n",
    "            print();\n",
    "            return np.zeros(shape=(100,))\n",
    "        else:\n",
    "            # return average word vector, for words in the document that exist in the vocab\n",
    "            return np.mean([model.wv.get_vector(word) for word in valid_words], axis=0)\n",
    "    except AttributeError:\n",
    "        return np.zeros(shape=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "bb6c89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_vecs = [get_avg_vec(doc) for doc in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d11cb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.DataFrame(avg_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "bd1c3358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10781, 100), (10781, 7))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df.shape, originaltweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4e73226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec = pd.concat([originaltweets, vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "638be411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec = df_vec.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3e6f925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "      <th>polarity</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416181616846811137</td>\n",
       "      <td>2021-07-16 23:43:03+00:00</td>\n",
       "      <td>üè° #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>rise slowly becoming normal which mean need re...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416181380279635970</td>\n",
       "      <td>2021-07-16 23:42:07+00:00</td>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>opportunity join fantastic team tech fast pace...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416181225979473920</td>\n",
       "      <td>2021-07-16 23:41:30+00:00</td>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>good news open this excellent report from remo...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>HK</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id            tweet_posted_on  \\\n",
       "0  1416181616846811137  2021-07-16 23:43:03+00:00   \n",
       "1  1416181380279635970  2021-07-16 23:42:07+00:00   \n",
       "2  1416181225979473920  2021-07-16 23:41:30+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  üè° #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  rise slowly becoming normal which mean need re...   \n",
       "1  opportunity join fantastic team tech fast pace...   \n",
       "2  good news open this excellent report from remo...   \n",
       "\n",
       "                    user_location user_location_cleaned  polarity    0    1  \\\n",
       "0                    New York, NY                    US         1  0.0  0.0   \n",
       "1               London | New York                    US         1  0.0  0.0   \n",
       "2  Sydney | Hong Kong | Singapore                    HK         1  0.0  0.0   \n",
       "\n",
       "     2  ...   90   91   92   93   94   95   96   97   98   99  \n",
       "0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 107 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "96ce9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_col = df_vec.columns[7:]\n",
    "vec_col_names = df_vec[vec_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4391b18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec=vec_col_names\n",
    "sc = StandardScaler()\n",
    "X_vec_sc = sc.fit_transform(X_vec)\n",
    "X_vec_sc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b8800272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-296-dbe8caf82279>:3: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(X_vec_sc)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-dbe8caf82279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_vec_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_vec_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_vec_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mlabel_freqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_number_of_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\"\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         raise ValueError(\"Number of labels is %d. Valid values are 2 \"\n\u001b[0m\u001b[1;32m     35\u001b[0m                          \"to n_samples - 1 (inclusive)\" % n_labels)\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "for i in range(3, 16):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(X_vec_sc)\n",
    "    print(i, kmeans.score(X_vec_sc), silhouette_score(X_vec_sc, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km_vec = KMeans(n_clusters=4, random_state=42)\n",
    "km_vec.fit(X_vec_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfa017",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_vec.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec['km']=km_vec.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec['km'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(X_vec_sc, km_vec.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_by_cluster = df_vec.groupby('km').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_by_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km_vec.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names()\n",
    "for i in range(14):\n",
    "    print (\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print( ' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7378722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
