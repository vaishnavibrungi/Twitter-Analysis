{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cdd067",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a07422",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4efe02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "import country_converter as coco\n",
    "import geonamescache\n",
    "import us\n",
    "import logging\n",
    "\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5755cf",
   "metadata": {},
   "source": [
    "**Read in both #workfromhome and #remotework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ff6ba2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfh_df = pd.read_csv(\"../dataset/tweet_df.csv\")\n",
    "rw_df = pd.read_csv(\"../dataset/remote_work.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fd734015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://catriscode.com/2021/03/02/extracting-or-removing-mentions-and-hashtags-in-tweets-using-python/\n",
    "#https://www.debuggex.com/cheatsheet/regex/python\n",
    "#https://stackoverflow.com/questions/50830214/remove-usernames-from-twitter-data-using-python/50830588\n",
    "#https://stackoverflow.com/questions/14081050/remove-all-forms-of-urls-from-a-given-string-in-python\n",
    "def remove_splchar(tweet):\n",
    "    tweet = tweet.lower() # Lowercases the string\n",
    "    tweet = re.sub('@[^\\s]+', ' ', tweet) # remove usernames\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', tweet) #remove URLs\n",
    "    tweet=re.sub('[^a-zA-Z#]', ' ', tweet) # remove special characters, numbers, punctuations\n",
    "    tweet = re.sub(\"#[A-Za-z0-9_]+\",\" \", tweet) #remove hashtags\n",
    "    tweet = re.sub(r\"\\s+\", \" \", str(tweet)) # replace double spaces with single space\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2463792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-spilt-a-sentence-into-list-of-words/\n",
    "#https://stackoverflow.com/questions/771918/how-do-i-do-word-stemming-or-lemmatization\n",
    "def lemmitize(tweet):\n",
    "    clean_column_list = []\n",
    "    wnl = WordNetLemmatizer()\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        clean_column_list.append(wnl.lemmatize(word)) \n",
    "    return \" \".join(clean_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d7cd72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Instantiate sentimnt analysis\n",
    "sent = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30b522fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get polarity score of each tweet\n",
    "def getPolarity(tweet):\n",
    "    polarity_dic = sent(tweet)\n",
    "    if polarity_dic[0]['label'] == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "61eac3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_by_country(code):\n",
    "    cities = []\n",
    "    for city in gc.get_cities().values():\n",
    "        if (city['countrycode'] == code) and (len(city['name']) > 3):\n",
    "            cities.append(city['name'])\n",
    "    return list(map(lambda x: x.lower(), cities));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5c09f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstates_citiesz_of_usa():\n",
    "    usa_state_names = [state.name.lower() for state in us.states.STATES_AND_TERRITORIES]\n",
    "    return get_cities_by_country('US') + usa_state_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "826c7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_state_cities_names = getstates_citiesz_of_usa()\n",
    "indian_cities = get_cities_by_country('IN')\n",
    "uk_cities = get_cities_by_country('GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b3c9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForUSA(location):\n",
    "    country = location;\n",
    "    if location.lower().find('usa') != -1 or location.lower().find('united states of america') != -1 or location.lower().find('united states') != -1:\n",
    "        country = 'USA'\n",
    "    elif us.states.lookup(location.split(',')[-1].strip()) != None  or  location.lower().find('america') != -1 or location.lower().find('u.s.a.') != -1:  \n",
    "        country = 'USA'\n",
    "    else:    \n",
    "        for state_city in usa_state_cities_names:\n",
    "            if location.lower().find(state_city) != -1:\n",
    "                country = 'USA'\n",
    "                break;\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "765d1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_india(location):\n",
    "    country = location;\n",
    "    if location.lower().find('india') != -1:\n",
    "        country = 'India'\n",
    "    else:    \n",
    "        for cities in indian_cities:\n",
    "            if location.lower().find(cities) != -1:\n",
    "                country = 'India'\n",
    "                break;\n",
    "    return country    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e2bbabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_uk(location):\n",
    "    country = location;\n",
    "    if location.lower().find('uk') != -1 or location.lower().find('britan') != -1 or location.lower().find('united kingdom') != -1:\n",
    "        country = 'United Kingdom'\n",
    "    else:    \n",
    "        for cities in uk_cities:\n",
    "            if location.lower().find(cities) != -1:\n",
    "                country = 'United Kingdom'\n",
    "                break;\n",
    "    return country    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "94503fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_others(location):\n",
    "    country = location;  \n",
    "    dicts = gc.get_countries_by_names();\n",
    "    for country_name,data in dicts.items():\n",
    "        if location.lower().find(country_name.lower()) != -1:\n",
    "            return country_name\n",
    "    return country  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950b382",
   "metadata": {},
   "source": [
    "**#workfromhome  dataframe cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a7f86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "wfh_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d4134641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quickly learn how to construct a really good c...</td>\n",
       "      <td>London, England</td>\n",
       "      <td>Fri Jul 16 22:34:40 +0000 2021</td>\n",
       "      <td>1416164405633499136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could YOU Fire Your Boss and Live the Dream? T...</td>\n",
       "      <td>Chapala, Jalisco, Mexico</td>\n",
       "      <td>Fri Jul 16 22:28:19 +0000 2021</td>\n",
       "      <td>1416162808379678722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are you exhausting yourself trying to make a s...</td>\n",
       "      <td>Jalisco, México-retired Iowan</td>\n",
       "      <td>Fri Jul 16 22:21:11 +0000 2021</td>\n",
       "      <td>1416161014496874498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  Quickly learn how to construct a really good c...   \n",
       "1  Could YOU Fire Your Boss and Live the Dream? T...   \n",
       "2  Are you exhausting yourself trying to make a s...   \n",
       "\n",
       "                   user_location                 tweet_posted_on  \\\n",
       "0                London, England  Fri Jul 16 22:34:40 +0000 2021   \n",
       "1       Chapala, Jalisco, Mexico  Fri Jul 16 22:28:19 +0000 2021   \n",
       "2  Jalisco, México-retired Iowan  Fri Jul 16 22:21:11 +0000 2021   \n",
       "\n",
       "              tweet_id  \n",
       "0  1416164405633499136  \n",
       "1  1416162808379678722  \n",
       "2  1416161014496874498  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to confirm if the column got deleted \n",
    "wfh_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4c6db9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5397, 4)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "wfh_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "df8bbc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             0\n",
       "user_location      0\n",
       "tweet_posted_on    0\n",
       "tweet_id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "wfh_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b2163edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             object\n",
       "user_location      object\n",
       "tweet_posted_on    object\n",
       "tweet_id            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatypes\n",
    "wfh_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b0fb6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column to be datetime dtype\n",
    "#https://stackoverflow.com/questions/50503033/remove-minutes-and-hours-from-series\n",
    "wfh_df['tweet_posted_on'] = pd.to_datetime(wfh_df['tweet_posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "74a9f588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['London, England', 'Chapala, Jalisco, Mexico',\n",
       "       'Jalisco, México-retired Iowan', ..., 'San Francisco, California ',\n",
       "       'Knoxville, TN', 'no where'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfh_df['user_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f3f088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/52673285/performance-of-pandas-apply-vs-np-vectorize-to-create-new-column-from-existing-c/52674448#52674448\n",
    "#Create a new column for processed tweets\n",
    "wfh_df['cleaned_tweets'] = np.vectorize(remove_splchar)(wfh_df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e19677b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of words which have more than 3 letters\n",
    "wfh_df['cleaned_tweets'] = wfh_df['cleaned_tweets'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e2f0fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place new lists of lemmitized words into the 'cleaned_tweets' column in the dataframe\n",
    "wfh_df['cleaned_tweets'] = wfh_df['cleaned_tweets'].map(lemmitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b32e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'polarity' to save tweet polarity score\n",
    "wfh_df['polarity'] = wfh_df['cleaned_tweets'].map(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e4e1e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column order\n",
    "wfh_df = wfh_df[['tweet_id','tweet_posted_on','tweets','cleaned_tweets','user_location','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7986505a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416164405633499136</td>\n",
       "      <td>2021-07-16 22:34:40+00:00</td>\n",
       "      <td>Quickly learn how to construct a really good c...</td>\n",
       "      <td>quickly learn construct really good want recei...</td>\n",
       "      <td>London, England</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416162808379678722</td>\n",
       "      <td>2021-07-16 22:28:19+00:00</td>\n",
       "      <td>Could YOU Fire Your Boss and Live the Dream? T...</td>\n",
       "      <td>could fire your bos live dream this waiter could</td>\n",
       "      <td>Chapala, Jalisco, Mexico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416161014496874498</td>\n",
       "      <td>2021-07-16 22:21:11+00:00</td>\n",
       "      <td>Are you exhausting yourself trying to make a s...</td>\n",
       "      <td>exhausting yourself trying make sale online wo...</td>\n",
       "      <td>Jalisco, México-retired Iowan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1416164405633499136 2021-07-16 22:34:40+00:00   \n",
       "1  1416162808379678722 2021-07-16 22:28:19+00:00   \n",
       "2  1416161014496874498 2021-07-16 22:21:11+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  Quickly learn how to construct a really good c...   \n",
       "1  Could YOU Fire Your Boss and Live the Dream? T...   \n",
       "2  Are you exhausting yourself trying to make a s...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  quickly learn construct really good want recei...   \n",
       "1   could fire your bos live dream this waiter could   \n",
       "2  exhausting yourself trying make sale online wo...   \n",
       "\n",
       "                   user_location  polarity  \n",
       "0                London, England         1  \n",
       "1       Chapala, Jalisco, Mexico         1  \n",
       "2  Jalisco, México-retired Iowan         0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe\n",
    "wfh_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b79baf",
   "metadata": {},
   "source": [
    "**#remotework dataframe cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d9770835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "rw_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9d93c3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🏡 #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Fri Jul 16 23:43:03 +0000 2021</td>\n",
       "      <td>1416181616846811137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>Fri Jul 16 23:42:07 +0000 2021</td>\n",
       "      <td>1416181380279635970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>Fri Jul 16 23:41:30 +0000 2021</td>\n",
       "      <td>1416181225979473920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  🏡 #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "\n",
       "                    user_location                 tweet_posted_on  \\\n",
       "0                    New York, NY  Fri Jul 16 23:43:03 +0000 2021   \n",
       "1               London | New York  Fri Jul 16 23:42:07 +0000 2021   \n",
       "2  Sydney | Hong Kong | Singapore  Fri Jul 16 23:41:30 +0000 2021   \n",
       "\n",
       "              tweet_id  \n",
       "0  1416181616846811137  \n",
       "1  1416181380279635970  \n",
       "2  1416181225979473920  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to confirm if the column got deleted \n",
    "rw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6f7c7abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5429, 4)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "rw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "57f7c1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             0\n",
       "user_location      0\n",
       "tweet_posted_on    0\n",
       "tweet_id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "rw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d4e50a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             object\n",
       "user_location      object\n",
       "tweet_posted_on    object\n",
       "tweet_id            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatypes\n",
    "rw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "40a7241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column to be datetime dtype\n",
    "rw_df['tweet_posted_on'] = pd.to_datetime(rw_df['tweet_posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7089d846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York, NY', 'London | New York',\n",
       "       'Sydney | Hong Kong | Singapore', ...,\n",
       "       'At home. Dressed comfortably.', 'Long Beach NY & NYC',\n",
       "       'Miami/LA '], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_df['user_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e3326d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column for processed tweets\n",
    "rw_df['cleaned_tweets'] = np.vectorize(remove_splchar)(rw_df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f4e68fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of words which have more than 3 letters\n",
    "rw_df['cleaned_tweets'] = rw_df['cleaned_tweets'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1f7fbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place new lists of lemmitized words into the 'cleaned_tweets' column in the dataframe\n",
    "rw_df['cleaned_tweets'] = rw_df['cleaned_tweets'].map(lemmitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b154611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'polarity' to save tweet polarity score\n",
    "rw_df['polarity'] = rw_df['cleaned_tweets'].map(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "78450e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column order\n",
    "rw_df = rw_df[['tweet_id','tweet_posted_on','tweets','cleaned_tweets','user_location','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "52285220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416181616846811137</td>\n",
       "      <td>2021-07-16 23:43:03+00:00</td>\n",
       "      <td>🏡 #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>rise slowly becoming normal which mean need re...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416181380279635970</td>\n",
       "      <td>2021-07-16 23:42:07+00:00</td>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>opportunity join fantastic team tech fast pace...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416181225979473920</td>\n",
       "      <td>2021-07-16 23:41:30+00:00</td>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>good news open this excellent report from remo...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1416181616846811137 2021-07-16 23:43:03+00:00   \n",
       "1  1416181380279635970 2021-07-16 23:42:07+00:00   \n",
       "2  1416181225979473920 2021-07-16 23:41:30+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  🏡 #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  rise slowly becoming normal which mean need re...   \n",
       "1  opportunity join fantastic team tech fast pace...   \n",
       "2  good news open this excellent report from remo...   \n",
       "\n",
       "                    user_location  polarity  \n",
       "0                    New York, NY         1  \n",
       "1               London | New York         1  \n",
       "2  Sydney | Hong Kong | Singapore         1  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe\n",
    "rw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751a0c4",
   "metadata": {},
   "source": [
    "### Merge both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aaab7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/python-intersection-two-lists/\n",
    "#Check number of rows that are common in both based on 'tweet_id'\n",
    "len(set(rw_df['tweet_id']).intersection(wfh_df['tweet_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef3bc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/21317384/pandas-python-how-to-concatenate-two-dataframes-without-duplicates\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "#Concatenate both datasets\n",
    "final_df = pd.concat([rw_df,wfh_df]).drop_duplicates(subset=['tweet_id'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "04626dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['user_location_cleaned'] = final_df['user_location'].astype(str).map(checkForUSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6fc7bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['user_location_cleaned'] = final_df['user_location_cleaned'].astype(str).map(check_for_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "84c6fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['user_location_cleaned'] = final_df['user_location_cleaned'].astype(str).map(check_for_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2c39bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['user_location_cleaned'] = final_df['user_location_cleaned'].astype(str).map(check_for_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7d0338b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_logger = coco.logging.getLogger()\n",
    "coco_logger.setLevel(logging.CRITICAL)\n",
    "final_df['user_location_cleaned'] = coco.convert(names=final_df['user_location_cleaned'].tolist(), to='ISO2', not_found='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4904dcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10234, 7)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "adb0cf87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>polarity</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416181616846811137</td>\n",
       "      <td>2021-07-16 23:43:03+00:00</td>\n",
       "      <td>🏡 #RemoteWork is on the rise &amp;amp; slowly beco...</td>\n",
       "      <td>rise slowly becoming normal which mean need re...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416181380279635970</td>\n",
       "      <td>2021-07-16 23:42:07+00:00</td>\n",
       "      <td>Opportunity to join a fantastic team at a hi-t...</td>\n",
       "      <td>opportunity join fantastic team tech fast pace...</td>\n",
       "      <td>London | New York</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416181225979473920</td>\n",
       "      <td>2021-07-16 23:41:30+00:00</td>\n",
       "      <td>Good news for #JobSeekers open to #RemoteWork!...</td>\n",
       "      <td>good news open this excellent report from remo...</td>\n",
       "      <td>Sydney | Hong Kong | Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1416181616846811137 2021-07-16 23:43:03+00:00   \n",
       "1  1416181380279635970 2021-07-16 23:42:07+00:00   \n",
       "2  1416181225979473920 2021-07-16 23:41:30+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  🏡 #RemoteWork is on the rise &amp; slowly beco...   \n",
       "1  Opportunity to join a fantastic team at a hi-t...   \n",
       "2  Good news for #JobSeekers open to #RemoteWork!...   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0  rise slowly becoming normal which mean need re...   \n",
       "1  opportunity join fantastic team tech fast pace...   \n",
       "2  good news open this excellent report from remo...   \n",
       "\n",
       "                    user_location  polarity user_location_cleaned  \n",
       "0                    New York, NY         1                    US  \n",
       "1               London | New York         1                    US  \n",
       "2  Sydney | Hong Kong | Singapore         1                    HK  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "71d7ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in a 'dataset' folder with a name 'final_df.csv'\n",
    "final_df.to_csv('../dataset/final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9170e29",
   "metadata": {},
   "source": [
    "### Merge data_11to19.csv to final_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "77f8f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in 'data_11to19.csv'\n",
    "data_from_11to19 = pd.read_csv(\"../dataset/data_from_11to19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "36177a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15504, 7)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "data_from_11to19.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "06689650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'user_location_cleaned' and map wherever user_location is mentioned as USA/usa/related locations to 'USA'\n",
    "data_from_11to19['user_location_cleaned'] = data_from_11to19['user_location'].astype(str).map(checkForUSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f34d2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_11to19['user_location_cleaned'] = data_from_11to19['user_location_cleaned'].astype(str).map(check_for_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f738d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_11to19['user_location_cleaned'] = data_from_11to19['user_location_cleaned'].astype(str).map(check_for_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3cbb9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_11to19['user_location_cleaned'] = data_from_11to19['user_location_cleaned'].astype(str).map(check_for_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fcf953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_logger = coco.logging.getLogger()\n",
    "coco_logger.setLevel(logging.CRITICAL)\n",
    "data_from_11to19['user_location_cleaned'] = coco.convert(names=data_from_11to19['user_location_cleaned'].tolist(), to='ISO2', not_found='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3bc324a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10073"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of rows that are common in both based on 'tweet_id'\n",
    "len(set(final_df['tweet_id']).intersection(data_from_11to19['tweet_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "54ea812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate both datasets\n",
    "final_df = pd.concat([final_df,data_from_11to19]).drop_duplicates(subset=['tweet_id'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cababd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in a 'dataset' folder with a name 'final_df.csv'\n",
    "final_df.to_csv('../dataset/final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe223d9",
   "metadata": {},
   "source": [
    "### Merge data_19to25.csv to final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eca915f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in 'data_19to25.csv'\n",
    "data_19to25 = pd.read_csv(\"../dataset/data_19to25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1915ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8177, 8)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape\n",
    "data_19to25.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "392b7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "data_19to25.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "239a01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of rows that are common in both based on 'tweet_id'\n",
    "len(set(final_df['tweet_id']).intersection(data_19to25['tweet_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "db3ca996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate both datasets\n",
    "final_df = pd.concat([final_df,data_19to25]).drop_duplicates(subset=['tweet_id'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "00bd517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in a 'dataset' folder with a name 'final_df.csv'\n",
    "final_df.to_csv('../dataset/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f2cb1118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22153, 8)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce3be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
