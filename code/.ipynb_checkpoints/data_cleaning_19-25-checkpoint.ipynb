{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cdd067",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a07422",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efe02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import pipeline\n",
    "import country_converter as coco\n",
    "import geonamescache\n",
    "import us\n",
    "import logging\n",
    "\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5755cf",
   "metadata": {},
   "source": [
    "**Read in both #workfromhome and #remotework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6ba2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfh_df_25 = pd.read_csv(\"../dataset/work_from_home_25.csv\")\n",
    "rw_df_25 = pd.read_csv(\"../dataset/remote_work_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd734015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://catriscode.com/2021/03/02/extracting-or-removing-mentions-and-hashtags-in-tweets-using-python/\n",
    "#https://www.debuggex.com/cheatsheet/regex/python\n",
    "#https://stackoverflow.com/questions/50830214/remove-usernames-from-twitter-data-using-python/50830588\n",
    "#https://stackoverflow.com/questions/14081050/remove-all-forms-of-urls-from-a-given-string-in-python\n",
    "def remove_splchar(tweet):\n",
    "    tweet = tweet.lower() # Lowercases the string\n",
    "    tweet = re.sub('@[^\\s]+', ' ', tweet) # remove usernames\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', tweet) #remove URLs\n",
    "    tweet=re.sub('[^a-zA-Z#]', ' ', tweet) # remove special characters, numbers, punctuations\n",
    "    tweet = re.sub(\"#[A-Za-z0-9_]+\",\" \", tweet) #remove hashtags\n",
    "    tweet = re.sub(r\"\\s+\", \" \", str(tweet)) # replace double spaces with single space\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2463792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-spilt-a-sentence-into-list-of-words/\n",
    "#https://stackoverflow.com/questions/771918/how-do-i-do-word-stemming-or-lemmatization\n",
    "def lemmitize(tweet):\n",
    "    clean_column_list = []\n",
    "    wnl = WordNetLemmatizer()\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        clean_column_list.append(wnl.lemmatize(word)) \n",
    "    return \" \".join(clean_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cd72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Instantiate sentimnt analysis\n",
    "sent = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b522fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get polarity score of each tweet\n",
    "def getPolarity(tweet):\n",
    "    polarity_dic = sent(tweet)\n",
    "    if polarity_dic[0]['label'] == 'POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61eac3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_by_country(code):\n",
    "    cities = []\n",
    "    for city in gc.get_cities().values():\n",
    "        if (city['countrycode'] == code) and (len(city['name']) > 3):\n",
    "            cities.append(city['name'])\n",
    "    return list(map(lambda x: x.lower(), cities));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c09f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstates_citiesz_of_usa():\n",
    "    usa_state_names = [state.name.lower() for state in us.states.STATES_AND_TERRITORIES]\n",
    "    return get_cities_by_country('US') + usa_state_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826c7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_state_cities_names = getstates_citiesz_of_usa()\n",
    "indian_cities = get_cities_by_country('IN')\n",
    "uk_cities = get_cities_by_country('GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3c9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForUSA(location):\n",
    "    country = location;\n",
    "    if location.lower().find('usa') != -1 or location.lower().find('united states of america') != -1 or location.lower().find('united states') != -1:\n",
    "        country = 'USA'\n",
    "    elif us.states.lookup(location.split(',')[-1].strip()) != None  or  location.lower().find('america') != -1 or location.lower().find('u.s.a.') != -1:  \n",
    "        country = 'USA'\n",
    "    else:    \n",
    "        for state_city in usa_state_cities_names:\n",
    "            if location.lower().find(state_city) != -1:\n",
    "                country = 'USA'\n",
    "                break;\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765d1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_india(location):\n",
    "    country = location;\n",
    "    if location.lower().find('india') != -1:\n",
    "        country = 'India'\n",
    "    else:    \n",
    "        for cities in indian_cities:\n",
    "            if location.lower().find(cities) != -1:\n",
    "                country = 'India'\n",
    "                break;\n",
    "    return country    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2bbabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_uk(location):\n",
    "    country = location;\n",
    "    if location.lower().find('uk') != -1 or location.lower().find('britan') != -1 or location.lower().find('united kingdom') != -1:\n",
    "        country = 'United Kingdom'\n",
    "    else:    \n",
    "        for cities in uk_cities:\n",
    "            if location.lower().find(cities) != -1:\n",
    "                country = 'United Kingdom'\n",
    "                break;\n",
    "    return country    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94503fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_others(location):\n",
    "    country = location;  \n",
    "    dicts = gc.get_countries_by_names();\n",
    "    for country_name,data in dicts.items():\n",
    "        if location.lower().find(country_name.lower()) != -1:\n",
    "            return country_name\n",
    "    return country  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950b382",
   "metadata": {},
   "source": [
    "**#workfromhome  dataframe cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7f86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "wfh_df_25.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4134641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @CloudDeskApp: For better or worse, working...</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Mon Jul 26 02:36:22 +0000 2021</td>\n",
       "      <td>1419486724623716355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For better or worse, working from home is here...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Mon Jul 26 02:35:57 +0000 2021</td>\n",
       "      <td>1419486619183116289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When it's #monday again but you just can't... ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Mon Jul 26 02:30:13 +0000 2021</td>\n",
       "      <td>1419485177458397189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets user_location  \\\n",
       "0  RT @CloudDeskApp: For better or worse, working...     Miami, FL   \n",
       "1  For better or worse, working from home is here...   Atlanta, GA   \n",
       "2  When it's #monday again but you just can't... ...     Singapore   \n",
       "\n",
       "                  tweet_posted_on             tweet_id  \n",
       "0  Mon Jul 26 02:36:22 +0000 2021  1419486724623716355  \n",
       "1  Mon Jul 26 02:35:57 +0000 2021  1419486619183116289  \n",
       "2  Mon Jul 26 02:30:13 +0000 2021  1419485177458397189  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to confirm if the column got deleted \n",
    "wfh_df_25.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c6db9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7193, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "wfh_df_25.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8bbc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             0\n",
       "user_location      0\n",
       "tweet_posted_on    0\n",
       "tweet_id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "wfh_df_25.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2163edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             object\n",
       "user_location      object\n",
       "tweet_posted_on    object\n",
       "tweet_id            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatypes\n",
    "wfh_df_25.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0fb6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column to be datetime dtype\n",
    "#https://stackoverflow.com/questions/50503033/remove-minutes-and-hours-from-series\n",
    "wfh_df_25['tweet_posted_on'] = pd.to_datetime(wfh_df_25['tweet_posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a9f588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Miami, FL', 'Atlanta, GA', 'Singapore', ...,\n",
       "       'Venezuela, Maracaibo', 'Stanley CupVille', 'Milwaukee, WI'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfh_df_25['user_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3f088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/52673285/performance-of-pandas-apply-vs-np-vectorize-to-create-new-column-from-existing-c/52674448#52674448\n",
    "#Create a new column for processed tweets\n",
    "wfh_df_25['cleaned_tweets'] = np.vectorize(remove_splchar)(wfh_df_25['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e19677b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of words which have more than 3 letters\n",
    "wfh_df_25['cleaned_tweets'] = wfh_df_25['cleaned_tweets'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f0fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place new lists of lemmitized words into the 'cleaned_tweets' column in the dataframe\n",
    "wfh_df_25['cleaned_tweets'] = wfh_df_25['cleaned_tweets'].map(lemmitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b32e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'polarity' to save tweet polarity score\n",
    "wfh_df_25['polarity'] = wfh_df_25['cleaned_tweets'].map(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4e1e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column order\n",
    "wfh_df_25 = wfh_df_25[['tweet_id','tweet_posted_on','tweets','cleaned_tweets','user_location','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7986505a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419486724623716355</td>\n",
       "      <td>2021-07-26 02:36:22+00:00</td>\n",
       "      <td>RT @CloudDeskApp: For better or worse, working...</td>\n",
       "      <td>better worse working from home here stay</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419486619183116289</td>\n",
       "      <td>2021-07-26 02:35:57+00:00</td>\n",
       "      <td>For better or worse, working from home is here...</td>\n",
       "      <td>better worse working from home here stay</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419485177458397189</td>\n",
       "      <td>2021-07-26 02:30:13+00:00</td>\n",
       "      <td>When it's #monday again but you just can't... ...</td>\n",
       "      <td>when again just</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1419486724623716355 2021-07-26 02:36:22+00:00   \n",
       "1  1419486619183116289 2021-07-26 02:35:57+00:00   \n",
       "2  1419485177458397189 2021-07-26 02:30:13+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  RT @CloudDeskApp: For better or worse, working...   \n",
       "1  For better or worse, working from home is here...   \n",
       "2  When it's #monday again but you just can't... ...   \n",
       "\n",
       "                             cleaned_tweets user_location  polarity  \n",
       "0  better worse working from home here stay     Miami, FL         0  \n",
       "1  better worse working from home here stay   Atlanta, GA         0  \n",
       "2                           when again just     Singapore         0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe\n",
    "wfh_df_25.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b79baf",
   "metadata": {},
   "source": [
    "**#remotework dataframe cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9770835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnamed: 0 column\n",
    "rw_df_25.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d93c3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>Jammu And Kashmir</td>\n",
       "      <td>Mon Jul 26 03:43:00 +0000 2021</td>\n",
       "      <td>1419503491010244610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>Prague</td>\n",
       "      <td>Mon Jul 26 03:42:58 +0000 2021</td>\n",
       "      <td>1419503485876326402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>Earth</td>\n",
       "      <td>Mon Jul 26 03:42:57 +0000 2021</td>\n",
       "      <td>1419503482483187713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets      user_location  \\\n",
       "0  RT @dnaRtests: Great speaker! Highly recommend...  Jammu And Kashmir   \n",
       "1  RT @dnaRtests: Great speaker! Highly recommend...             Prague   \n",
       "2  RT @dnaRtests: Great speaker! Highly recommend...              Earth   \n",
       "\n",
       "                  tweet_posted_on             tweet_id  \n",
       "0  Mon Jul 26 03:43:00 +0000 2021  1419503491010244610  \n",
       "1  Mon Jul 26 03:42:58 +0000 2021  1419503485876326402  \n",
       "2  Mon Jul 26 03:42:57 +0000 2021  1419503482483187713  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to confirm if the column got deleted \n",
    "rw_df_25.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f7c7abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5124, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "rw_df_25.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57f7c1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             0\n",
       "user_location      0\n",
       "tweet_posted_on    0\n",
       "tweet_id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "rw_df_25.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d4e50a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets             object\n",
       "user_location      object\n",
       "tweet_posted_on    object\n",
       "tweet_id            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatypes\n",
    "rw_df_25.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40a7241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column to be datetime dtype\n",
    "rw_df_25['tweet_posted_on'] = pd.to_datetime(rw_df_25['tweet_posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7089d846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jammu And Kashmir', 'Prague', 'Earth', 'Kenya', 'India',\n",
       "       'Sri Lanka', 'Grand Blanc, MI', 'Chicago, IL',\n",
       "       'USA|EUROPE|ASIA|GLOBAL✈️', 'Worldwide', 'Ottawa Canada', 'World',\n",
       "       'twitter', '🇺🇸 M.4.G.4.🇺🇸  IFB4P 🦅 🏈', 'Berlin, Germany',\n",
       "       'Waterloo, Ontario Canada', 'Hamburg', 'Sarrbrüken',\n",
       "       'Fort Lauderdale, FL', 'Melbourne', 'Toronto, Ontario, Canada',\n",
       "       'United Kingdom UK GB', 'Internet', 'New Jersey', 'Portland, OR',\n",
       "       'Turn 🔔 Notifications ON ', 'Global', 'Canada CA', 'Manila', 'USA',\n",
       "       'Remote', 'London | New York', \"Town 'n' Country, FL\",\n",
       "       'Atlanta Metro Area', 'Pittsburgh, PA', 'Calgary, Alberta', 'Lsk ',\n",
       "       'New York City', 'Medellin, Colombia ', 'Westport, CT',\n",
       "       'London, England', 'anywhere 🌍 / Born in Tokyo🗼', 'NY',\n",
       "       'West & Central Africa', 'Việt Nam', 'Bay Shore, NY',\n",
       "       'Newark, Delaware USA', 'Miami, FL', 'Washington, DC', 'maryland',\n",
       "       'Australia', 'The Zoo, MT', 'W.A.T.P. uk', 'Berlin, Deutschland',\n",
       "       'Patchogue, NY', 'Washington, USA', 'Atlanta, GA', 'Ohio',\n",
       "       'God’s promise land ', 'Charlotte, NC', 'United States of America',\n",
       "       'Ottawa.  Toronto. Canada', 'Atlanta', 'WeaTheMoneyResides',\n",
       "       'Carnegie, VIC, AU, 3163', 'Ex-NY’er in search of liberty',\n",
       "       'Menlo Park, CA', 'Jacksonville, FL',\n",
       "       'South East Cork, Munster, ROI', 'New York, NY',\n",
       "       'Milano, Lombardia', 'LON | NYC | HKG  | SYD | SIN', 'Dallas, TX',\n",
       "       'United States', 'Plant City, FL', 'Global Offices', 'Lithia, FL',\n",
       "       'Kolkata, West Bengal', 'United States US', 'Los Gatos, CA',\n",
       "       'metro Detroit, Michigan', 'Online Directory',\n",
       "       'Colorado Front Range -Bldr/Dvr', 'All over', 'Turkey / İstanbul',\n",
       "       'South Florida, USA', 'NYC', 'Web', 'Everywhere', 'Las Vegas, NV',\n",
       "       'Shanghai, China', 'poland Thorn East Europe',\n",
       "       'Frankfurt on the Main, Germany', 'Texas / Digital Nomad',\n",
       "       'New York', 'Paris, France', 'Lagos, Nigeria',\n",
       "       'Reading, England, Europe', 'Toronto, Ontario',\n",
       "       'Silicon Valley & beyond', 'Denver, Colorado Worldwide',\n",
       "       'The High Seas', 'Sandpoint, ID', 'Frederick, MD', 'Los Angeles',\n",
       "       'New York, New York', 'Boston, MA', 'Southampton, UK', 'Nigeria',\n",
       "       'North Carolina, USA', 'Cape Coast, Ghana', 'VA',\n",
       "       'Orange County, California', 'San Diego, CA', 'Global Citizen',\n",
       "       'drifting on waves.', 'Anywhere', 'Nashville, TN',\n",
       "       'Chicago, Illinois', 'monkeytown', 'Waterloo, Ontario', 'Ireland',\n",
       "       'Nomad (ish)', 'United Kingdom', 'U.K.', 'California', '127.0.0.1',\n",
       "       'Maui, HI', 'Pune, India', 'Sacramento, CA', 'Nebraska, USA',\n",
       "       'Rivers, Nigeria', 'Omaha, NE', 'Wyoming, USA', 'Cyprus',\n",
       "       'Mississauga, ON', 'Chiyoda-ku, Tokyo', 'San Jose, CA',\n",
       "       'Mission Viejo, CA', 'Ecuador', 'Lodwar', 'Nederland',\n",
       "       'Slakertown USA', 'Gandhinagar, India', 'Chassell, MI',\n",
       "       'Leningrad, USSR', 'Barnstable, MA', 'Dunedin, FL',\n",
       "       'Los Angeles, California', 'Depends on the day', 'Gunter Texas',\n",
       "       'Help us!', 'the internet', 'Phnom Penh, Cambodia', 'Bristol',\n",
       "       '#RemoteWork #Boston ', 'Ontario, CA', 'Europe', 'Boise, ID',\n",
       "       'New Canaan, CT', 'Kentucky, USA', 'Mechelen, Belgie',\n",
       "       'Western Australia', 'in the Cloud', 'Los Angeles, CA',\n",
       "       'Milan, Lombardy', 'Boston, MA | Everywhere', '🇯🇵 Hokkaido',\n",
       "       'Bucharest', 'kota', 'Bay Area, CA', 'INDIA', 'UAE', 'Toronto',\n",
       "       'Denver, CO', 'Waterville, Maine 04901', 'Abuja Nigeria',\n",
       "       'That Swanky 47th room', 'Far East Asia', 'Miami Beach, FL',\n",
       "       'Palo Alto, CA', 'everywhere', 'Montreal, Canada',\n",
       "       'Coimbatore / Bangalore', 'Memphis, TN', 'Jackson, MI',\n",
       "       'Chris@firstbaseHQ.com', 'Montreal', 'Aldgate, London E1',\n",
       "       '🇫🇷 France and 🇲🇨 Monaco  ', 'Portland Oregon', 'Miami, FL USA',\n",
       "       'Lebanon ', 'Hyderabad, India', 'Lebanon', 'Tampa, Florida',\n",
       "       'Dublin City, Ireland', 'Republic of the Philippines',\n",
       "       'Hollywood, FL', 'Cancún, Quintana Roo, México', 'Chicago, USA',\n",
       "       'Buffalo, NY', 'Budapest, Hungary', 'Greater Detroit Area',\n",
       "       'Germany', 'Hometown', 'Jakarta Capital Region', 'Africa',\n",
       "       'TMO Towers', 'Leicester | Birmingham | London',\n",
       "       'Colchester, England', 'here', 'I live on cloud', 'Coding World!',\n",
       "       '☁️', 'Lucknow', 'Writing to inspire startups ', 'New York ',\n",
       "       'Global ', 'In Transit Right Now ',\n",
       "       'Egham, Sheffield and Cambridge', 'Colorado, USA', 'India ',\n",
       "       'Tallinn, Estonia', 'Dublin & Galway, Ireland',\n",
       "       ' WolverhamptonLondon EnglandUK', 'Belgium', 'Rio de janeiro',\n",
       "       'Surrey UK', 'Twitter Universe', 'GLOBAL', 'Bengaluru',\n",
       "       'East, England', 'منڈی بوریوالہ, پاکستان', 'Pakistan',\n",
       "       'London, UK', 'Singapore, Singapore', 'New Delhi, India', ' 👉👉',\n",
       "       'California, USA', 'Queensland, Australia', 'Florida',\n",
       "       'Philadelphia, PA', 'Fort Huachuca, AZ', '서울/경기',\n",
       "       'Brits, South Africa', 'Dubai, UAE', 'Caracas', 'Centennial, CO',\n",
       "       'Guayaquil, Ecuador', 'Belgium, USA, Pakistan',\n",
       "       'Australia | Philippines', 'Everywhere, Earth', 'Rochester, NY',\n",
       "       'Austin, TX', 'Anchorage, Alaska', 'Sydney, New South Wales',\n",
       "       'Washington, D.C.', '\\uf8ff', 'Italy', 'Texas, USA',\n",
       "       'Philadelphia, Pa', 'San Jose CA', 'Turkey', 'London',\n",
       "       'Houston, TX', 'Rutland, MA', 'Leicester, England, Mauritius',\n",
       "       'Transilvania', 'Austin, Texas', 'Dorset, UK', 'Hong Kong',\n",
       "       'Las Cruces, NM', 'Azabudai', 'EnThroned ', 'Ruby World',\n",
       "       'Hogwarts, Always', 'Seattle, Washington', 'Rosemont, IL', 'Spain',\n",
       "       'NOLA', 'SiliconDelta, USA', 'Porto, Portugal',\n",
       "       'Bristol, Cambridge, and remote', 'São Paulo',\n",
       "       'British Columbia, Canada', 'Boulder, CO', 'Fort Worth, TX',\n",
       "       'Kansas, USA', 'Overland Park, KS', 'Japan', 'Buenos Aires',\n",
       "       'Columbus, OH', 'San Francisco, CA', 'South Dakota, (East River)',\n",
       "       'GA ✈️✈️MZANSI', 'Ottawa, Ontario', 'Indianapolis, Indiana',\n",
       "       'Redwood City, CA', 'Mumbai, India', 'Aussie in Europe',\n",
       "       'In the Mind of God. ✌', 'Virginia, USA', 'West Los Angeles',\n",
       "       'South Florida', 'State College, PA', 'Somewhere',\n",
       "       'Gainesville, FL', 'south florida', 'Bogotá, D.C., Colombia',\n",
       "       'Kalamazoo and Battle Creek, MI', 'DC',\n",
       "       'Amsterdam, The Netherlands', 'Boynton Beach, Florida'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_df_25['user_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e3326d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column for processed tweets\n",
    "rw_df_25['cleaned_tweets'] = np.vectorize(remove_splchar)(rw_df_25['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4e68fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of words which have more than 3 letters\n",
    "rw_df_25['cleaned_tweets'] = rw_df_25['cleaned_tweets'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f7fbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place new lists of lemmitized words into the 'cleaned_tweets' column in the dataframe\n",
    "rw_df_25['cleaned_tweets'] = rw_df_25['cleaned_tweets'].map(lemmitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b154611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column 'polarity' to save tweet polarity score\n",
    "rw_df_25['polarity'] = rw_df_25['cleaned_tweets'].map(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78450e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column order\n",
    "rw_df_25 = rw_df_25[['tweet_id','tweet_posted_on','tweets','cleaned_tweets','user_location','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52285220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419503491010244610</td>\n",
       "      <td>2021-07-26 03:43:00+00:00</td>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>great speaker highly recommend daysofcode</td>\n",
       "      <td>Jammu And Kashmir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419503485876326402</td>\n",
       "      <td>2021-07-26 03:42:58+00:00</td>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>great speaker highly recommend daysofcode</td>\n",
       "      <td>Prague</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419503482483187713</td>\n",
       "      <td>2021-07-26 03:42:57+00:00</td>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>great speaker highly recommend daysofcode</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1419503491010244610 2021-07-26 03:43:00+00:00   \n",
       "1  1419503485876326402 2021-07-26 03:42:58+00:00   \n",
       "2  1419503482483187713 2021-07-26 03:42:57+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  RT @dnaRtests: Great speaker! Highly recommend...   \n",
       "1  RT @dnaRtests: Great speaker! Highly recommend...   \n",
       "2  RT @dnaRtests: Great speaker! Highly recommend...   \n",
       "\n",
       "                              cleaned_tweets      user_location  polarity  \n",
       "0  great speaker highly recommend daysofcode  Jammu And Kashmir         1  \n",
       "1  great speaker highly recommend daysofcode             Prague         1  \n",
       "2  great speaker highly recommend daysofcode              Earth         1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe\n",
    "rw_df_25.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751a0c4",
   "metadata": {},
   "source": [
    "### Merge both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aaab7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/python-intersection-two-lists/\n",
    "#Check number of rows that are common in both based on 'tweet_id'\n",
    "len(set(rw_df_25['tweet_id']).intersection(wfh_df_25['tweet_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef3bc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/21317384/pandas-python-how-to-concatenate-two-dataframes-without-duplicates\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "#Concatenate both datasets\n",
    "data_19to25 = pd.concat([rw_df_25,wfh_df_25]).drop_duplicates(subset=['tweet_id'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0195eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_19to25['user_location_cleaned'] = data_19to25['user_location'].map(checkForUSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6df73fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_19to25['user_location_cleaned'] = data_19to25['user_location_cleaned'].map(check_for_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "056ed5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_19to25['user_location_cleaned'] = data_19to25['user_location_cleaned'].map(check_for_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48acdff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_19to25['user_location_cleaned'] = data_19to25['user_location_cleaned'].map(check_for_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0e24ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_logger = coco.logging.getLogger()\n",
    "coco_logger.setLevel(logging.CRITICAL)\n",
    "data_19to25['user_location_cleaned'] = coco.convert(names=data_19to25['user_location_cleaned'].tolist(), to='ISO2', not_found='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4904dcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8177, 7)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "data_19to25.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "adb0cf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_posted_on</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>user_location</th>\n",
       "      <th>polarity</th>\n",
       "      <th>user_location_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419503491010244610</td>\n",
       "      <td>2021-07-26 03:43:00+00:00</td>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>great speaker highly recommend daysofcode</td>\n",
       "      <td>Jammu And Kashmir</td>\n",
       "      <td>1</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419503485876326402</td>\n",
       "      <td>2021-07-26 03:42:58+00:00</td>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>great speaker highly recommend daysofcode</td>\n",
       "      <td>Prague</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419503482483187713</td>\n",
       "      <td>2021-07-26 03:42:57+00:00</td>\n",
       "      <td>RT @dnaRtests: Great speaker! Highly recommend...</td>\n",
       "      <td>great speaker highly recommend daysofcode</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_posted_on  \\\n",
       "0  1419503491010244610 2021-07-26 03:43:00+00:00   \n",
       "1  1419503485876326402 2021-07-26 03:42:58+00:00   \n",
       "2  1419503482483187713 2021-07-26 03:42:57+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  RT @dnaRtests: Great speaker! Highly recommend...   \n",
       "1  RT @dnaRtests: Great speaker! Highly recommend...   \n",
       "2  RT @dnaRtests: Great speaker! Highly recommend...   \n",
       "\n",
       "                              cleaned_tweets      user_location  polarity  \\\n",
       "0  great speaker highly recommend daysofcode  Jammu And Kashmir         1   \n",
       "1  great speaker highly recommend daysofcode             Prague         1   \n",
       "2  great speaker highly recommend daysofcode              Earth         1   \n",
       "\n",
       "  user_location_cleaned  \n",
       "0                    IN  \n",
       "1                  None  \n",
       "2                  None  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_19to25.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71d7ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in a 'dataset' folder with a name 'final_df.csv'\n",
    "data_19to25.to_csv('../dataset/data_19to25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b802f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
